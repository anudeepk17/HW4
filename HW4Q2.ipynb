{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpSPB2AlS7Fw"
      },
      "source": [
        "Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7VUZsZw_S7Fz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "everychars = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
        "everylang = ['e','j','s']\n",
        "Language={'e':'English','j':'Japanese','s':'Spanish'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L9q7eAPS7F0"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_btINzekS7F0"
      },
      "outputs": [],
      "source": [
        "train_X = []\n",
        "train_Y = []\n",
        "\n",
        "for i,lang in enumerate(everylang):\n",
        "    for N in range(10):\n",
        "        with open(f\"{lang}{N}.txt\",'r+') as f:\n",
        "            txt = f.readlines()\n",
        "        txt = ''.join(txt)\n",
        "        txt = Counter(txt)\n",
        "        txt = [txt[i] for i in everychars]\n",
        "        train_X.append(txt)\n",
        "        train_Y.append(i)\n",
        "train_X = np.asarray(train_X)\n",
        "train_Y = np.asarray(train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvdz2kxOS7F1",
        "outputId": "b67efb84-7b26-4097-f57f-e605883f7cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06016851 0.01113497 0.02151    0.02197258 0.10536924 0.01893276\n",
            " 0.01747894 0.04721626 0.05541054 0.00142078 0.00373369 0.02897737\n",
            " 0.02051875 0.05792169 0.0644639  0.01675202 0.0005617  0.05382455\n",
            " 0.06618206 0.08012556 0.02666446 0.00928465 0.01549645 0.00115645\n",
            " 0.01384437 0.00062779 0.17924996]\n"
          ]
        }
      ],
      "source": [
        "all_english = train_X[train_Y==0]\n",
        "count_english = np.sum(all_english,axis=0)\n",
        "count_english = count_english+0.5\n",
        "prob_eng = count_english/sum(count_english)\n",
        "print(prob_eng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnaNDwRoS7F1"
      },
      "source": [
        "### Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_-VJ3_fS7F2",
        "outputId": "69074cae-3778-4121-fa86-6a86a37ae834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.31765610e-01 1.08669066e-02 5.48586603e-03 1.72263182e-02\n",
            " 6.02047591e-02 3.87854223e-03 1.40116706e-02 3.17621161e-02\n",
            " 9.70334393e-02 2.34110207e-03 5.74094133e-02 1.43261470e-03\n",
            " 3.97987351e-02 5.67105769e-02 9.11632132e-02 8.73545547e-04\n",
            " 1.04825466e-04 4.28037318e-02 4.21747790e-02 5.69901115e-02\n",
            " 7.06174220e-02 2.44592753e-04 1.97421294e-02 3.49418219e-05\n",
            " 1.41514379e-02 7.72214263e-03 1.23449457e-01]\n"
          ]
        }
      ],
      "source": [
        "all_japan = train_X[train_Y==1]\n",
        "count_japan = np.sum(all_japan,axis=0)\n",
        "count_japan = count_japan+0.5\n",
        "prob_jap = count_japan/sum(count_japan)\n",
        "print(prob_jap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW9dvE73S7F2",
        "outputId": "cc5c862c-704d-459a-9f8f-25272306575a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.04560451e-01 8.23286362e-03 3.75258241e-02 3.97459221e-02\n",
            " 1.13810860e-01 8.60287996e-03 7.18448398e-03 4.53270019e-03\n",
            " 4.98597021e-02 6.62945947e-03 2.77512257e-04 5.29431717e-02\n",
            " 2.58086399e-02 5.41765595e-02 7.24923684e-02 2.42669051e-02\n",
            " 7.67783910e-03 5.92951189e-02 6.57704049e-02 3.56140730e-02\n",
            " 3.37023219e-02 5.88942678e-03 9.25040856e-05 2.49761031e-03\n",
            " 7.86284728e-03 2.68261848e-03 1.68264932e-01]\n"
          ]
        }
      ],
      "source": [
        "all_spain = train_X[train_Y==2]\n",
        "count_spain = np.sum(all_spain,axis=0)\n",
        "count_spain = count_spain+0.5\n",
        "prob_spa = count_spain/sum(count_spain)\n",
        "print(prob_spa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XOV0SZsS7F2"
      },
      "source": [
        "### Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVthuuLzS7F3",
        "outputId": "3e906b4f-2dcd-4a4d-ec10-3996edb66610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[164, 32, 53, 57, 311, 55, 51, 140, 140, 3, 6, 85, 64, 139, 182, 53, 3, 141, 186, 225, 65, 31, 47, 4, 38, 2, 498]\n"
          ]
        }
      ],
      "source": [
        "with open(\"e10.txt\",'r+') as f:\n",
        "    txt = f.readlines()\n",
        "    txt = ''.join(txt)\n",
        "    txt = Counter(txt)\n",
        "\n",
        "bag_e10 = [txt[i] for i in everychars]\n",
        "print(bag_e10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7hgoKYqS7F3"
      },
      "source": [
        "### Question 5 and 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edOFvZ6mS7F3",
        "outputId": "4962cbd2-faee-4193-d4ea-2b978281a149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7841.865447060635 -8771.433079075032 -8467.282044010557\n",
            "Predicted class is 'English'\n"
          ]
        }
      ],
      "source": [
        "p_eng = sum(bag_e10*np.log(prob_eng))\n",
        "p_spa = sum(bag_e10*np.log(prob_spa))\n",
        "p_jap = sum(bag_e10*np.log(prob_jap))\n",
        "print(p_eng, p_jap, p_spa)\n",
        "print(f\"Predicted class is \\'{Language[everylang[np.argmax([p_eng, p_jap, p_spa])]]}\\'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGXhW8LRS7F3"
      },
      "source": [
        "### Question 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yJWJ-85ES7F4"
      },
      "outputs": [],
      "source": [
        "test_X = []\n",
        "test_Y = []\n",
        "for i,lang in enumerate(['e','j','s']):\n",
        "    for N in range(10,20):\n",
        "        with open(f\"{lang}{N}.txt\",'r+') as f:\n",
        "            txt = f.readlines()\n",
        "        txt = ''.join(txt)\n",
        "        txt = Counter(txt)\n",
        "        txt = [txt[i] for i in everychars]\n",
        "        test_X.append(txt)\n",
        "        test_Y.append(i)\n",
        "test_X = np.asarray(test_X)\n",
        "test_Y = np.asarray(test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dSBMcCBnS7F4"
      },
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "for x in test_X:\n",
        "    p_eng = sum(x*np.log(prob_eng))\n",
        "    p_spa = sum(x*np.log(prob_spa))\n",
        "    p_jap = sum(x*np.log(prob_jap))\n",
        "    y_pred.append(np.argmax([p_eng, p_jap, p_spa]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg4bd-JMS7F4",
        "outputId": "b15b76f5-b020-4312-eabe-d57b8e8738ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\tEng\tJap\tSpa\n",
            "Eng\t10\t0\t0\n",
            "Jap\t0\t10\t0\n",
            "Spa\t0\t0\t10\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix\")\n",
        "print(\"\\tEng\\tJap\\tSpa\")\n",
        "confmat = confusion_matrix(test_Y,y_pred)\n",
        "print(f\"Eng\\t{confmat[0][0]}\\t{confmat[0][1]}\\t{confmat[0][2]}\")\n",
        "print(f\"Jap\\t{confmat[1][0]}\\t{confmat[1][1]}\\t{confmat[1][2]}\")\n",
        "print(f\"Spa\\t{confmat[2][0]}\\t{confmat[2][1]}\\t{confmat[2][2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21F8U19OS7F4"
      },
      "source": [
        "### Question 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lynNCEp6S7F5",
        "outputId": "c4c98ad8-b36b-4616-efe9-5ca18aa37e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Original Text===\n",
            "mou sugu subetega aoi kemurini umorete ikuno\n",
            "\n",
            "\n",
            "\n",
            "utsumuita kimiwo terashiteiku\n",
            "\n",
            "asuwa kitto mirare masu youni\n",
            "\n",
            "anatanoa shini ginnoashiwo hamemashou\n",
            "\n",
            "muneno naka wakidasu izumi\n",
            "\n",
            "yobi samase  inochiwo\n",
            "\n",
            "fuki susabu arashide  are hateta chino uede\n",
            "\n",
            "nanimo kowakunai  kimiga nozondeita\n",
            "\n",
            "\n",
            "\n",
            "sunani kakareta  shiono michi hikiwo\n",
            "\n",
            "kieteku senakani  chigireru hodo tewo furu\n",
            "\n",
            "nejireta   saigono yoruni\n",
            "\n",
            "togireta uta   tsuzuki wo oshiete\n",
            "\n",
            "\n",
            "\n",
            "kishimu karadawo atatameru monowa kono ryoute dake\n",
            "\n",
            "ikiwo hisomete furueteru dakeno bokuno\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zutto konomama zutto daiteitai  \n",
            "\n",
            "usodemo himitsudemo kamawanainda rakuenwo kimini ageru\n",
            "\n",
            "amaku kanashii barano nioi gashita\n",
            "\n",
            "\n",
            "\n",
            "  \n",
            "\n",
            "furue irowo nakushite yuku\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sayonaratte ienakatta koto itsuka yurushitene  \n",
            "\n",
            "hizamazuku tsuchino ue tsumetai sekihini\n",
            "\n",
            "nakitsukareta kokorowa tada samayoi tsuzukeru\n",
            "\n",
            "yasashii kaze fuwari\n",
            "\n",
            "\n",
            "\n",
            "subetewo sutetemade mezashita rakuen  \n",
            "\n",
            "\n",
            "\n",
            "fukurandewa mata haretsushite  \n",
            "\n",
            "nisouno funewa suberi dashite yuku  \n",
            "\n",
            "hitasura muneni kasanete yukou\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tomatta sekaide maboroshiwo dakishimeru\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "akaku akaku kyouwo someru\n",
            "\n",
            "kikimorasanaide  \n",
            "\n",
            "torinokosarete uzukumatta  \n",
            "\n",
            "chimamireno mamade daiteokure  \n",
            "\n",
            "anatano hanewo chigiri sutete shimaimashou  \n",
            "\n",
            "aseruhodo karamitsuku yumetoiu kumono ito  \n",
            "\n",
            "taiyousae todokudarou  \n",
            "\n",
            "\n",
            "\n",
            "daremo shiranai hateni ikou\n",
            "\n",
            "kimikara koboreru kotobano subetega  \n",
            "\n",
            "yasurakana ameni nurerumade  \n",
            "\n",
            "nee nanimo mienaikara tsuyoku daiteite  \n",
            "\n",
            "negaigoto tataete   moeteiruno\n",
            "\n",
            "\n",
            "===Shuffeled Text===\n",
            "a fantnn d \n",
            "be nwwan\n",
            "hio h iuiatsh  akh a\n",
            "rhms a\n",
            "achouauo  eur\n",
            "mm ousoot\n",
            "iwnya ieez\n",
            "e\n",
            "\n",
            "aaokaoik n der\n",
            "dsin oaw\n",
            "ehreuuoaieaotoushtoe\n",
            " rni muuik\n",
            "si enrmgn \n",
            "ma\n",
            "\n",
            "h\n",
            "\n",
            "ua k i urim i\n",
            "anai km\n",
            "\n",
            "aw sk\n",
            "\n",
            "ucota aabtt\n",
            "ue di \n",
            "isir e yadbi ia ik ik\n",
            "\n",
            "ucs\n",
            "\n",
            "arou\n",
            "  aa si\n",
            "\n",
            "n t   ho im \n",
            "derky aoihu nkye\n",
            "  smrtoeaeeak aua ie\n",
            "ar\n",
            "\n",
            "\n",
            "rukmaakoauoi\n",
            "eaoeumaa iae\n",
            "sg\n",
            "oiekzu a  ni\n",
            "\n",
            "\n",
            "aa\n",
            "rtintord ednouity uigtaruokamumsuyiaoah\n",
            "\n",
            "\n",
            "r haa \n",
            "essotwo eikbrawadrsir\n",
            "oifi oetudhrinen\n",
            "iamftneaua\n",
            "ioann\n",
            "nmtiiiuaas nneut ioioinfnsi oaah  aosrne astin\n",
            "niukraaa twauehko\n",
            "ka  ko\n",
            "esr e\n",
            "y na\n",
            "ra oz\n",
            "unoihmaa aettmidkibntzroaws iegi  en ia n\n",
            " hiiu\n",
            "bmm keuauut\n",
            "ort\n",
            "tnuthonmaefikaan\n",
            "dtkikuiukbo\n",
            "suezdetrt ahhk\n",
            "snouaaoaes\n",
            "t\n",
            "to momteddeaitaahuuyneuemeoh\n",
            " ears krtki\n",
            "au\n",
            "er u itse o sae setuu\n",
            " omhmomsueku\n",
            "ktezwomtrmkinnh ouiaahai\n",
            "h  iudtadeceoihkuoe\n",
            "oouiu gecrhuhkutom\n",
            "ay u outaktuiihshiosusta titokaysae rkk ww\n",
            "t mk\n",
            "uoudkitis aatwieemhttmos iar iseo troeotn\n",
            "tia au\n",
            "toto\n",
            "iyaa\n",
            "ztak rmuk aauea a k siosi e hmizskaadtweuda unazuot  \n",
            "b ik ua\n",
            "o\n",
            "ksyioko\n",
            " wnm\n",
            "kam u\n",
            "acan\n",
            "auan\n",
            "ing\n",
            "aksniaakimua\n",
            "u\n",
            "iuhiifeuenj\n",
            "ugiektuuto o gk\n",
            "n\n",
            "t\n",
            "yodetso a  mhsaikuftey naorhanganaoiueiwoih ent  i  \n",
            "a \n",
            "m\n",
            "szeauuetra unearuomkaaiik\n",
            "mioti\n",
            "iu\n",
            "runa oes uninadireoieeauai geos\n",
            "\n",
            "set mmiriuoaaeietne eteioomoetsoa\n",
            "ga ru ekbwonma\n",
            "iuuawmuohew\n",
            "urrieodoedukeskek\n",
            "  am\n",
            "ntktdrt a  oku  i smomdii e\n",
            "nkets\n",
            "trrzuwos\n",
            "wet  \n",
            "nenobsara ik\n",
            "n ssu\n",
            "onko rt aunr\n",
            "itaoaiont w suataaoyhssmia\n",
            " cmsugstik kswaeue\n",
            "kmoka mu arukhksr nbmkaeouids e\n",
            "te    e o krtsnmtygrrn\n",
            "\n",
            "====================\n",
            "\n",
            "-4038.260470015417 -3671.8278627563272 -4379.278643487949\n",
            "Predicted class is 'Japanese'\n"
          ]
        }
      ],
      "source": [
        "with open(\"j6.txt\",'r+') as f:\n",
        "    txt = f.readlines()\n",
        "    txt = ''.join(txt)\n",
        "    print(\"===Original Text===\")\n",
        "    print(txt)\n",
        "    temp = list(txt)\n",
        "    random.shuffle(temp)\n",
        "    txt = ''.join(temp)\n",
        "    print(\"===Shuffeled Text===\")\n",
        "    print(txt)\n",
        "    txt = Counter(txt)\n",
        "print(\"\\n====================\\n\")\n",
        "bag_e10 = [txt[i] for i in everychars]\n",
        "\n",
        "p_eng = sum(bag_e10*np.log(prob_eng))\n",
        "p_spa = sum(bag_e10*np.log(prob_spa))\n",
        "p_jap = sum(bag_e10*np.log(prob_jap))\n",
        "print(p_eng, p_jap, p_spa)\n",
        "print(f\"Predicted class is \\'{Language[everylang[np.argmax([p_eng, p_jap, p_spa])]]}\\'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}